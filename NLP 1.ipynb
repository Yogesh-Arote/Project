{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b57bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (1.20.3)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (2.9.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (0.1.9)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (0.4.5)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (2.26.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.4)\n",
      "Requirement already satisfied: SpeechRecognition in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy\n",
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d0fad57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e5543c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.2.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (8.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click<8.1.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b577a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in D:/USB-DS/E/Audio_file.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Python code to convert video to audio\n",
    "import moviepy.editor as mp\n",
    "# Insert Local Video File Path\n",
    "clip = mp.VideoFileClip(r\"D:/USB-DS/E/10-2.mp4\")\n",
    "\n",
    "# Insert Local Audio File Path\n",
    "audio_clip= clip.audio.write_audiofile(r\"D:/USB-DS/E/Audio_file.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0bceced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32948c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_large_audio_transcription(path):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_wav(path)  \n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                print(chunk_filename, \":\", text)\n",
    "                whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e629c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-chunks\\chunk1.wav : What's so important about. \n",
      "audio-chunks\\chunk2.wav : This teenage maintaining a healthy business girls hand in hand alongside working with tailor. \n",
      "audio-chunks\\chunk3.wav : Whether you understand it or not. \n",
      "audio-chunks\\chunk4.wav : There is no denying that area is at the foundation of any successful company and the business entrepreneur was that a leading the way you are aware that looking deeper into data is what would make them tower above the competition. \n",
      "audio-chunks\\chunk5.wav : Word start with the data team or the big data team. \n",
      "audio-chunks\\chunk6.wav : Deva mata song bye business problem. \n",
      "audio-chunks\\chunk7.wav : The theme of a significant work on the data that is available first. \n",
      "audio-chunks\\chunk8.wav : Based on that the business intelligence team of providing business insights dashboard. \n",
      "audio-chunks\\chunk9.wav : After the dashboard is very the data science team ou sem business analytics or data analytics tools to develop models predict future outcomes. \n",
      "Error: \n",
      "audio-chunks\\chunk11.wav : What time we talking about. \n",
      "audio-chunks\\chunk12.wav : And what's your data science will get. \n",
      "audio-chunks\\chunk13.wav : Speaking words are the dictionary in sticking together at random. \n",
      "audio-chunks\\chunk14.wav : No. \n",
      "audio-chunks\\chunk15.wav : These are actual data science buzzwords in animal that. \n",
      "audio-chunks\\chunk16.wav : There are many other similar phrases. \n",
      "audio-chunks\\chunk17.wav : No wonder you are confused. \n",
      "Error: \n",
      "audio-chunks\\chunk19.wav : Why not. \n",
      "audio-chunks\\chunk20.wav : Is completely understandable for you to feel like this. \n",
      "audio-chunks\\chunk21.wav : Worksheet some light as you have things became so complicated. \n",
      "audio-chunks\\chunk22.wav : One can say this confusion is the constant evolution of the data science industry and in turn the meaning of these passwords. \n",
      "audio-chunks\\chunk23.wav : This complicates the situation a lot. \n",
      "audio-chunks\\chunk24.wav : For example someone who had the time statistician 25 years ago. \n",
      "audio-chunks\\chunk25.wav : Would it be responsible for gathering and cleaning data sets and applying there is statistical methods to the data. \n",
      "audio-chunks\\chunk26.wav : Aap to some mutable with the growth of data in the vehicle improvement of technology. \n",
      "audio-chunks\\chunk27.wav : This station would now be required to extract parents from data in sport and new buzzword was coined. \n",
      "audio-chunks\\chunk28.wav : Reminding. \n",
      "audio-chunks\\chunk29.wav : Forward my nephew more years in the same statistician due to new mathematical and statistical models can perform more accurate forecast. \n",
      "audio-chunks\\chunk30.wav : 121 already inflated business glossary. \n",
      "audio-chunks\\chunk31.wav : Predictive analytics. \n",
      "audio-chunks\\chunk32.wav : Station change to japan this point. \n",
      "Error: \n",
      "audio-chunks\\chunk34.wav : Gold different. \n",
      "Error: \n",
      "audio-chunks\\chunk36.wav : Not really. \n",
      "audio-chunks\\chunk37.wav : However she is more qualified now to be part of the statistics department predictive analytics team or have the title data scientist. \n",
      "audio-chunks\\chunk38.wav : How to play it easy to see now these passwords develop over time and have someone who would qualify as a statistician 25 years ago and had kept up with modern technologies. \n",
      "audio-chunks\\chunk39.wav : Patentwire multitude of professional categories now. \n",
      "audio-chunks\\chunk40.wav : Interesting. \n",
      "audio-chunks\\chunk41.wav : But messi right. \n",
      "audio-chunks\\chunk42.wav : Cause of confusion with stems from the one just mentioned. \n",
      "audio-chunks\\chunk43.wav : Comes from hr managers to understand a boy can become overwhelmed with the newton's and passwords flying around. \n",
      "audio-chunks\\chunk44.wav : This causes them till i want job positions in arekere. \n",
      "audio-chunks\\chunk45.wav : 10 seeming like your choosing a mono where am i. \n",
      "audio-chunks\\chunk46.wav : Hr representative mein college job position data analytic specialist when in fat. \n",
      "audio-chunks\\chunk47.wav : They need data analyst. \n",
      "audio-chunks\\chunk48.wav : Another name for junior data scientist whenever required a business intelligence analyst. \n",
      "audio-chunks\\chunk49.wav : Course there are many companies that burn the job offers. \n",
      "audio-chunks\\chunk50.wav : This is not standard across the board. \n",
      "audio-chunks\\chunk51.wav : Which can cause even more famous. \n",
      "Error: \n",
      "audio-chunks\\chunk53.wav : Exemplified already. \n",
      "audio-chunks\\chunk54.wav : What are the data in theatres science can seem overwhelming very well make you want to run away and hide from anything they related. \n",
      "Error: \n",
      "audio-chunks\\chunk56.wav : Devatas longer. \n",
      "audio-chunks\\chunk57.wav : 365 data science team are here to help you sold to the clever in c data science in a whole new rider lily light. \n",
      "audio-chunks\\chunk58.wav : We have designed a unique and for graphic to put everything together. \n",
      "audio-chunks\\chunk59.wav : You can search the internet for different stories. \n",
      "audio-chunks\\chunk60.wav : Baat. \n",
      "audio-chunks\\chunk61.wav : Time. \n",
      "audio-chunks\\chunk62.wav : Vikas you find in aggregated concise and to the point structure containing all the technical and business terms that are frequently used in the field of data science. \n",
      "audio-chunks\\chunk63.wav : Vigyan bike fire fighting the similarities and differences between the terms business in a lyrics. \n",
      "audio-chunks\\chunk64.wav : Innova olx. \n",
      "audio-chunks\\chunk65.wav : Dega science. \n",
      "audio-chunks\\chunk66.wav : Business intelligence. \n",
      "audio-chunks\\chunk67.wav : Indian machine learning. \n",
      "audio-chunks\\chunk68.wav : Then we focus on helping you digest the definitions you need now in an effective way. \n",
      "Error: \n",
      "audio-chunks\\chunk70.wav : Up more than capable of being able to relate in the various expressions and passwords to the areas of data science they belong to. \n",
      "audio-chunks\\chunk71.wav : So what are you waiting for let's dive strident. \n"
     ]
    }
   ],
   "source": [
    "text = get_large_audio_transcription(\"D:/USB-DS/E/Audio_file.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9b9a294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "#from spacy.en import English\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecd6ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a92a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_words=list(STOP_WORDS)+list(punctuation)+['\\n']\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "docx = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b823c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=[word.text for word in docx]\n",
    "Freq_word={}\n",
    "for w in all_words:\n",
    "    w1=w.lower()\n",
    "    if w1 not in extra_words and w1.isalpha():\n",
    "        if w1 in Freq_word.keys():\n",
    "            Freq_word[w1]+=1\n",
    "        else:\n",
    "            Freq_word[w1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "Freq_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d29fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val=sorted(Freq_word.values())\n",
    "max_freq=val[-4:]\n",
    "print(\"Topic of document given :-\")\n",
    "for word,freq in Freq_word.items():\n",
    "    if freq in max_freq:\n",
    "        print(word ,end=\" \")\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in Freq_word.keys():\n",
    "       Freq_word[word] = (Freq_word[word]/max_freq[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae46493",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_strength={}\n",
    "for sent in docx.sents:\n",
    "    for word in sent :\n",
    "        if word.text.lower() in Freq_word.keys():\n",
    "            if sent in sent_strength.keys():\n",
    "                sent_strength[sent]+=Freq_word[word.text.lower()]\n",
    "            else:\n",
    "                sent_strength[sent]=Freq_word[word.text.lower()]\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b144fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c2b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sentences=(sorted(sent_strength.values())[::-1])\n",
    "top20percent_sentence=int(0.2*len(top_sentences))\n",
    "top_sent=top_sentences[:top20percent_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a222bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=[]\n",
    "for sent,strength in sent_strength.items():\n",
    "    if strength in top_sent:\n",
    "        summary.append(sent)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a016081",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in summary:\n",
    "    print(i,end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
